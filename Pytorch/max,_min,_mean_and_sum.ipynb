{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GawddwK0vLEe",
        "outputId": "2394724c-d049-4b0e-f593-0d0dbb59210e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***MAX:***"
      ],
      "metadata": {
        "id": "MmLW2hpMx3LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.max.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up_9vU1jEjGU",
        "outputId": "54bdebc5-97b8-4deb-8a72-3d77aa7acc4c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "max(input) -> Tensor\n",
            "\n",
            "Returns the maximum value of all elements in the ``input`` tensor.\n",
            "\n",
            ".. warning::\n",
            "    This function produces deterministic (sub)gradients unlike ``max(dim=0)``\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> a = torch.randn(1, 3)\n",
            "    >>> a\n",
            "    tensor([[ 0.6763,  0.7445, -2.2369]])\n",
            "    >>> torch.max(a)\n",
            "    tensor(0.7445)\n",
            "\n",
            ".. function:: max(input, dim, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
            "   :noindex:\n",
            "\n",
            "Returns a namedtuple ``(values, indices)`` where ``values`` is the maximum\n",
            "value of each row of the :attr:`input` tensor in the given dimension\n",
            ":attr:`dim`. And ``indices`` is the index location of each maximum value found\n",
            "(argmax).\n",
            "\n",
            "If ``keepdim`` is ``True``, the output tensors are of the same size\n",
            "as ``input`` except in the dimension ``dim`` where they are of size 1.\n",
            "Otherwise, ``dim`` is squeezed (see :func:`torch.squeeze`), resulting\n",
            "in the output tensors having 1 fewer dimension than ``input``.\n",
            "\n",
            ".. note:: If there are multiple maximal values in a reduced row then\n",
            "          the indices of the first maximal value are returned.\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "    dim (int): the dimension to reduce.\n",
            "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not. Default: ``False``.\n",
            "\n",
            "Keyword args:\n",
            "    out (tuple, optional): the result tuple of two output tensors (max, max_indices)\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> a = torch.randn(4, 4)\n",
            "    >>> a\n",
            "    tensor([[-1.2360, -0.2942, -0.1222,  0.8475],\n",
            "            [ 1.1949, -1.1127, -2.2379, -0.6702],\n",
            "            [ 1.5717, -0.9207,  0.1297, -1.8768],\n",
            "            [-0.6172,  1.0036, -0.6060, -0.2432]])\n",
            "    >>> torch.max(a, 1)\n",
            "    torch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1]))\n",
            "\n",
            ".. function:: max(input, other, *, out=None) -> Tensor\n",
            "   :noindex:\n",
            "\n",
            "See :func:`torch.maximum`.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten = torch.rand(3,3)\n",
        "\n",
        "print(a_ten)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJAFaz-k-mA9",
        "outputId": "8f5a5c48-e0be-4923-ccb9-1d0a8398954c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1469, 0.6676, 0.4281],\n",
            "        [0.4400, 0.9072, 0.7605],\n",
            "        [0.1003, 0.5113, 0.7870]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten.max()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We2FtiLMDef6",
        "outputId": "2d9fdd55-b8e5-429b-b383-af8f0f7d47fb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9072)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(a_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bm2UcTODibU",
        "outputId": "cfa065c8-b863-4955-d8ed-0619c3c23186"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9072)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(a_ten, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kp5b-CyZGUlf",
        "outputId": "58820ce9-71cf-4a29-b564-254df07ccc0b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([0.4400, 0.9072, 0.7870]),\n",
              "indices=tensor([1, 1, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(a_ten, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKREi0R_Gi6j",
        "outputId": "13da8983-054b-4794-fc87-71369189d36c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([0.6676, 0.9072, 0.7870]),\n",
              "indices=tensor([1, 1, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Min:***"
      ],
      "metadata": {
        "id": "2dix4Z4ACmZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.min.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1OU00CfEuYK",
        "outputId": "3edba642-bb32-48e4-ab3e-38929dc51729"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "min(input) -> Tensor\n",
            "\n",
            "Returns the minimum value of all elements in the :attr:`input` tensor.\n",
            "\n",
            ".. warning::\n",
            "    This function produces deterministic (sub)gradients unlike ``min(dim=0)``\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> a = torch.randn(1, 3)\n",
            "    >>> a\n",
            "    tensor([[ 0.6750,  1.0857,  1.7197]])\n",
            "    >>> torch.min(a)\n",
            "    tensor(0.6750)\n",
            "\n",
            ".. function:: min(input, dim, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
            "   :noindex:\n",
            "\n",
            "Returns a namedtuple ``(values, indices)`` where ``values`` is the minimum\n",
            "value of each row of the :attr:`input` tensor in the given dimension\n",
            ":attr:`dim`. And ``indices`` is the index location of each minimum value found\n",
            "(argmin).\n",
            "\n",
            "If :attr:`keepdim` is ``True``, the output tensors are of the same size as\n",
            ":attr:`input` except in the dimension :attr:`dim` where they are of size 1.\n",
            "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\n",
            "the output tensors having 1 fewer dimension than :attr:`input`.\n",
            "\n",
            ".. note:: If there are multiple minimal values in a reduced row then\n",
            "          the indices of the first minimal value are returned.\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "    dim (int): the dimension to reduce.\n",
            "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
            "\n",
            "Keyword args:\n",
            "    out (tuple, optional): the tuple of two output tensors (min, min_indices)\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> a = torch.randn(4, 4)\n",
            "    >>> a\n",
            "    tensor([[-0.6248,  1.1334, -1.1899, -0.2803],\n",
            "            [-1.4644, -0.2635, -0.3651,  0.6134],\n",
            "            [ 0.2457,  0.0384,  1.0128,  0.7015],\n",
            "            [-0.1153,  2.9849,  2.1458,  0.5788]])\n",
            "    >>> torch.min(a, 1)\n",
            "    torch.return_types.min(values=tensor([-1.1899, -1.4644,  0.0384, -0.1153]), indices=tensor([2, 0, 1, 0]))\n",
            "\n",
            ".. function:: min(input, other, *, out=None) -> Tensor\n",
            "   :noindex:\n",
            "\n",
            "See :func:`torch.minimum`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC10i3SJCxGy",
        "outputId": "2ce23d2f-cb5b-492b-c785-50070889d9c1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1003)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(a_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57x13gqpEKWL",
        "outputId": "15d0fa95-226d-4e80-ce8a-1cf825bad52f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1003)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(a_ten, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnTjcy7EG6BP",
        "outputId": "189d7e1a-a706-4ec7-fc39-4b1c1682b877"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.min(\n",
              "values=tensor([0.1003, 0.5113, 0.4281]),\n",
              "indices=tensor([2, 2, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.min(a_ten, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px8RuefNG90h",
        "outputId": "7a0771e3-d00e-45f6-e3eb-6e09426cc396"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.min(\n",
              "values=tensor([0.1469, 0.4400, 0.1003]),\n",
              "indices=tensor([0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Mean:***"
      ],
      "metadata": {
        "id": "-LSnDZ_WCww0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.mean.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5L4LDt6ExBV",
        "outputId": "0585b385-9a48-4f51-bd10-5832ae6d4eee"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "mean(input, *, dtype=None) -> Tensor\n",
            "\n",
            "Returns the mean value of all elements in the :attr:`input` tensor. Input must be floating point or complex.\n",
            "\n",
            "Args:\n",
            "    input (Tensor):\n",
            "      the input tensor, either of floating point or complex dtype\n",
            "\n",
            "Keyword args:\n",
            "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "        If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
            "        is performed. This is useful for preventing data type overflows. Default: None.\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> a = torch.randn(1, 3)\n",
            "    >>> a\n",
            "    tensor([[ 0.2294, -0.5481,  1.3288]])\n",
            "    >>> torch.mean(a)\n",
            "    tensor(0.3367)\n",
            "\n",
            ".. function:: mean(input, dim, keepdim=False, *, dtype=None, out=None) -> Tensor\n",
            "   :noindex:\n",
            "\n",
            "Returns the mean value of each row of the :attr:`input` tensor in the given\n",
            "dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
            "reduce over all of them.\n",
            "\n",
            "\n",
            "If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
            "as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
            "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
            "output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
            "\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "    dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
            "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
            "\n",
            "Keyword args:\n",
            "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "        If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
            "        is performed. This is useful for preventing data type overflows. Default: None.\n",
            "    out (Tensor, optional): the output tensor.\n",
            "\n",
            ".. seealso::\n",
            "\n",
            "    :func:`torch.nanmean` computes the mean value of `non-NaN` elements.\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> a = torch.randn(4, 4)\n",
            "    >>> a\n",
            "    tensor([[-0.3841,  0.6320,  0.4254, -0.7384],\n",
            "            [-0.9644,  1.0131, -0.6549, -1.4279],\n",
            "            [-0.2951, -1.3350, -0.7694,  0.5600],\n",
            "            [ 1.0842, -0.9580,  0.3623,  0.2343]])\n",
            "    >>> torch.mean(a, 1)\n",
            "    tensor([-0.0163, -0.5085, -0.4599,  0.1807])\n",
            "    >>> torch.mean(a, 1, True)\n",
            "    tensor([[-0.0163],\n",
            "            [-0.5085],\n",
            "            [-0.4599],\n",
            "            [ 0.1807]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0J2Pum0C7HJ",
        "outputId": "3474aedc-be39-40bd-cd2f-dc984eebc1ca"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5277)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(a_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5pV7vh_EQeK",
        "outputId": "5fd09f4e-0f47-4bd6-f78e-7c8a71ab75a0"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5277)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(a_ten, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNx8isd2HLSP",
        "outputId": "c0e2b9d9-a34e-4be2-8556-d43cb9bdc8fa"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2291, 0.6954, 0.6585])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(a_ten, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMt2EREeHOb8",
        "outputId": "32a29cb1-7a6e-4db3-9869-3fa1697348d3"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4142, 0.7025, 0.4662])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Sum:***"
      ],
      "metadata": {
        "id": "75XMXA1qC7rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.sum.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqsFzM2JE0Qj",
        "outputId": "6cb6e8af-bd9d-477f-eedf-92ce1d27cf34"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "sum(input, *, dtype=None) -> Tensor\n",
            "\n",
            "Returns the sum of all elements in the :attr:`input` tensor.\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "\n",
            "Keyword args:\n",
            "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "        If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
            "        is performed. This is useful for preventing data type overflows. Default: None.\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> a = torch.randn(1, 3)\n",
            "    >>> a\n",
            "    tensor([[ 0.1133, -0.9567,  0.2958]])\n",
            "    >>> torch.sum(a)\n",
            "    tensor(-0.5475)\n",
            "\n",
            ".. function:: sum(input, dim, keepdim=False, *, dtype=None) -> Tensor\n",
            "   :noindex:\n",
            "\n",
            "Returns the sum of each row of the :attr:`input` tensor in the given\n",
            "dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
            "reduce over all of them.\n",
            "\n",
            "\n",
            "If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
            "as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
            "Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
            "output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
            "\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "    \n",
            "    dim (int or tuple of ints, optional): the dimension or dimensions to reduce.\n",
            "        If ``None``, all dimensions are reduced.\n",
            "\n",
            "    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
            "\n",
            "Keyword args:\n",
            "    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "        If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
            "        is performed. This is useful for preventing data type overflows. Default: None.\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> a = torch.randn(4, 4)\n",
            "    >>> a\n",
            "    tensor([[ 0.0569, -0.2475,  0.0737, -0.3429],\n",
            "            [-0.2993,  0.9138,  0.9337, -1.6864],\n",
            "            [ 0.1132,  0.7892, -0.1003,  0.5688],\n",
            "            [ 0.3637, -0.9906, -0.4752, -1.5197]])\n",
            "    >>> torch.sum(a, 1)\n",
            "    tensor([-0.4598, -0.1381,  1.3708, -2.6217])\n",
            "    >>> b = torch.arange(4 * 5 * 6).view(4, 5, 6)\n",
            "    >>> torch.sum(b, (2, 1))\n",
            "    tensor([  435.,  1335.,  2235.,  3135.])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(a_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9blwBzyaEV6_",
        "outputId": "6efb154e-8f92-482e-c100-d6ac80e7bdd4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.7489)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(a_ten, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfFBOUOYFS5n",
        "outputId": "a9c190a5-ab46-488e-e45b-609b3a9bdd1a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6872, 2.0861, 1.9756])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(a_ten, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3OuTi8XHxOe",
        "outputId": "bb04af07-9b92-4ea7-fafa-de37769f065a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.2426, 2.1076, 1.3986])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(a_ten, dim=0, keepdim=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f7H3vfvHz-f",
        "outputId": "7bf35f2c-e19b-40d6-8234-7b78c745ca69"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6872, 2.0861, 1.9756]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rUCKlPWeH2ln"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}