{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GawddwK0vLEe",
        "outputId": "2394724c-d049-4b0e-f593-0d0dbb59210e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Addition:***"
      ],
      "metadata": {
        "id": "MmLW2hpMx3LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.add.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up_9vU1jEjGU",
        "outputId": "81942e1b-9d56-464b-d661-ffd73ff4aa19"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "add(input, other, *, alpha=1, out=None) -> Tensor\n",
            "\n",
            "Adds :attr:`other`, scaled by :attr:`alpha`, to :attr:`input`.\n",
            "\n",
            ".. math::\n",
            "    \\text{{out}}_i = \\text{{input}}_i + \\text{{alpha}} \\times \\text{{other}}_i\n",
            "\n",
            "\n",
            "Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
            ":ref:`type promotion <type-promotion-doc>`, and integer, float, and complex inputs.\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "    other (Tensor or Number): the tensor or number to add to :attr:`input`.\n",
            "\n",
            "Keyword arguments:\n",
            "    alpha (Number): the multiplier for :attr:`other`.\n",
            "    out (Tensor, optional): the output tensor.\n",
            "\n",
            "Examples::\n",
            "\n",
            "    >>> a = torch.randn(4)\n",
            "    >>> a\n",
            "    tensor([ 0.0202,  1.0985,  1.3506, -0.6056])\n",
            "    >>> torch.add(a, 20)\n",
            "    tensor([ 20.0202,  21.0985,  21.3506,  19.3944])\n",
            "\n",
            "    >>> b = torch.randn(4)\n",
            "    >>> b\n",
            "    tensor([-0.9732, -0.3497,  0.6245,  0.4022])\n",
            "    >>> c = torch.randn(4, 1)\n",
            "    >>> c\n",
            "    tensor([[ 0.3743],\n",
            "            [-1.7724],\n",
            "            [-0.5811],\n",
            "            [-0.8017]])\n",
            "    >>> torch.add(b, c, alpha=10)\n",
            "    tensor([[  2.7695,   3.3930,   4.3672,   4.1450],\n",
            "            [-18.6971, -18.0736, -17.0994, -17.3216],\n",
            "            [ -6.7845,  -6.1610,  -5.1868,  -5.4090],\n",
            "            [ -8.9902,  -8.3667,  -7.3925,  -7.6147]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten = torch.rand(3,3)\n",
        "b_ten = torch.rand(3,3)\n",
        "print(a_ten)\n",
        "print(b_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJAFaz-k-mA9",
        "outputId": "68abbcc6-0f40-4ae3-b7ac-3615e0c6f491"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3566, 0.3438, 0.9721],\n",
            "        [0.6952, 0.5105, 0.1676],\n",
            "        [0.8754, 0.4529, 0.0531]])\n",
            "tensor([[0.6180, 0.5561, 0.8785],\n",
            "        [0.2979, 0.8358, 0.5954],\n",
            "        [0.7297, 0.8821, 0.7257]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten + b_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We2FtiLMDef6",
        "outputId": "a0591eb4-624b-4f92-b4fb-36f2e1ee44d4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9746, 0.8999, 1.8506],\n",
              "        [0.9931, 1.3463, 0.7630],\n",
              "        [1.6050, 1.3350, 0.7788]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.add(a_ten, b_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bm2UcTODibU",
        "outputId": "3950b2cf-c6ef-47b1-83c7-11f421c7dc35"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9746, 0.8999, 1.8506],\n",
              "        [0.9931, 1.3463, 0.7630],\n",
              "        [1.6050, 1.3350, 0.7788]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Subtraction:***"
      ],
      "metadata": {
        "id": "2dix4Z4ACmZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.sub.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1OU00CfEuYK",
        "outputId": "25dd1bd9-f45e-4f10-c93e-8e399870abb5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "sub(input, other, *, alpha=1, out=None) -> Tensor\n",
            "\n",
            "Subtracts :attr:`other`, scaled by :attr:`alpha`, from :attr:`input`.\n",
            "\n",
            ".. math::\n",
            "    \\text{{out}}_i = \\text{{input}}_i - \\text{{alpha}} \\times \\text{{other}}_i\n",
            "\n",
            "\n",
            "Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
            ":ref:`type promotion <type-promotion-doc>`, and integer, float, and complex inputs.\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "    other (Tensor or Number): the tensor or number to subtract from :attr:`input`.\n",
            "\n",
            "Keyword args:\n",
            "    alpha (Number): the multiplier for :attr:`other`.\n",
            "    out (Tensor, optional): the output tensor.\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> a = torch.tensor((1, 2))\n",
            "    >>> b = torch.tensor((0, 1))\n",
            "    >>> torch.sub(a, b, alpha=2)\n",
            "    tensor([1, 0])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten - b_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC10i3SJCxGy",
        "outputId": "e958b77a-2a2c-47cb-8cde-00d10e6911f7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2614, -0.2123,  0.0936],\n",
              "        [ 0.3973, -0.3253, -0.4277],\n",
              "        [ 0.1457, -0.4292, -0.6727]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sub(a_ten, b_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57x13gqpEKWL",
        "outputId": "600432a7-930f-4950-829c-fd2b7921f002"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2614, -0.2123,  0.0936],\n",
              "        [ 0.3973, -0.3253, -0.4277],\n",
              "        [ 0.1457, -0.4292, -0.6727]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Multiplication:***"
      ],
      "metadata": {
        "id": "-LSnDZ_WCww0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.mul.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5L4LDt6ExBV",
        "outputId": "cd65f3ac-b3cc-4a7b-cf89-283a81948fbd"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "mul(input, other, *, out=None) -> Tensor\n",
            "\n",
            "Multiplies :attr:`input` by :attr:`other`.\n",
            "\n",
            "\n",
            ".. math::\n",
            "    \\text{out}_i = \\text{input}_i \\times \\text{other}_i\n",
            "\n",
            "\n",
            "Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
            ":ref:`type promotion <type-promotion-doc>`, and integer, float, and complex inputs.\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the input tensor.\n",
            "    other (Tensor or Number) - the tensor or number to multiply input by.\n",
            "\n",
            "Keyword args:\n",
            "    out (Tensor, optional): the output tensor.\n",
            "\n",
            "Examples::\n",
            "\n",
            "    >>> a = torch.randn(3)\n",
            "    >>> a\n",
            "    tensor([ 0.2015, -0.4255,  2.6087])\n",
            "    >>> torch.mul(a, 100)\n",
            "    tensor([  20.1494,  -42.5491,  260.8663])\n",
            "\n",
            "    >>> b = torch.randn(4, 1)\n",
            "    >>> b\n",
            "    tensor([[ 1.1207],\n",
            "            [-0.3137],\n",
            "            [ 0.0700],\n",
            "            [ 0.8378]])\n",
            "    >>> c = torch.randn(1, 4)\n",
            "    >>> c\n",
            "    tensor([[ 0.5146,  0.1216, -0.5244,  2.2382]])\n",
            "    >>> torch.mul(b, c)\n",
            "    tensor([[ 0.5767,  0.1363, -0.5877,  2.5083],\n",
            "            [-0.1614, -0.0382,  0.1645, -0.7021],\n",
            "            [ 0.0360,  0.0085, -0.0367,  0.1567],\n",
            "            [ 0.4312,  0.1019, -0.4394,  1.8753]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten * b_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0J2Pum0C7HJ",
        "outputId": "6f62c176-5f24-4f2e-f181-9fbcb8b6c93e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2204, 0.1912, 0.8539],\n",
              "        [0.2071, 0.4267, 0.0998],\n",
              "        [0.6387, 0.3995, 0.0385]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mul(a_ten, b_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5pV7vh_EQeK",
        "outputId": "af5047c4-2399-4828-f1a0-87cf164b78e6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2204, 0.1912, 0.8539],\n",
              "        [0.2071, 0.4267, 0.0998],\n",
              "        [0.6387, 0.3995, 0.0385]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Division:***"
      ],
      "metadata": {
        "id": "75XMXA1qC7rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.div.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqsFzM2JE0Qj",
        "outputId": "ca5e9b16-a019-4ae4-bbdd-8a21ccf285e2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "div(input, other, *, rounding_mode=None, out=None) -> Tensor\n",
            "\n",
            "Divides each element of the input ``input`` by the corresponding element of\n",
            ":attr:`other`.\n",
            "\n",
            ".. math::\n",
            "    \\text{out}_i = \\frac{\\text{input}_i}{\\text{other}_i}\n",
            "\n",
            ".. note::\n",
            "    By default, this performs a \"true\" division like Python 3.\n",
            "    See the :attr:`rounding_mode` argument for floor division.\n",
            "\n",
            "Supports :ref:`broadcasting to a common shape <broadcasting-semantics>`,\n",
            ":ref:`type promotion <type-promotion-doc>`, and integer, float, and complex inputs.\n",
            "Always promotes integer types to the default scalar type.\n",
            "\n",
            "Args:\n",
            "    input (Tensor): the dividend\n",
            "    other (Tensor or Number): the divisor\n",
            "\n",
            "Keyword args:\n",
            "    rounding_mode (str, optional): Type of rounding applied to the result:\n",
            "\n",
            "        * None - default behavior. Performs no rounding and, if both :attr:`input` and\n",
            "          :attr:`other` are integer types, promotes the inputs to the default scalar type.\n",
            "          Equivalent to true division in Python (the ``/`` operator) and NumPy's ``np.true_divide``.\n",
            "        * ``\"trunc\"`` - rounds the results of the division towards zero.\n",
            "          Equivalent to C-style integer division.\n",
            "        * ``\"floor\"`` - rounds the results of the division down.\n",
            "          Equivalent to floor division in Python (the ``//`` operator) and NumPy's ``np.floor_divide``.\n",
            "\n",
            "    out (Tensor, optional): the output tensor.\n",
            "\n",
            "Examples::\n",
            "\n",
            "    >>> x = torch.tensor([ 0.3810,  1.2774, -0.2972, -0.3719,  0.4637])\n",
            "    >>> torch.div(x, 0.5)\n",
            "    tensor([ 0.7620,  2.5548, -0.5944, -0.7438,  0.9274])\n",
            "\n",
            "    >>> a = torch.tensor([[-0.3711, -1.9353, -0.4605, -0.2917],\n",
            "    ...                   [ 0.1815, -1.0111,  0.9805, -1.5923],\n",
            "    ...                   [ 0.1062,  1.4581,  0.7759, -1.2344],\n",
            "    ...                   [-0.1830, -0.0313,  1.1908, -1.4757]])\n",
            "    >>> b = torch.tensor([ 0.8032,  0.2930, -0.8113, -0.2308])\n",
            "    >>> torch.div(a, b)\n",
            "    tensor([[-0.4620, -6.6051,  0.5676,  1.2639],\n",
            "            [ 0.2260, -3.4509, -1.2086,  6.8990],\n",
            "            [ 0.1322,  4.9764, -0.9564,  5.3484],\n",
            "            [-0.2278, -0.1068, -1.4678,  6.3938]])\n",
            "\n",
            "    >>> torch.div(a, b, rounding_mode='trunc')\n",
            "    tensor([[-0., -6.,  0.,  1.],\n",
            "            [ 0., -3., -1.,  6.],\n",
            "            [ 0.,  4., -0.,  5.],\n",
            "            [-0., -0., -1.,  6.]])\n",
            "\n",
            "    >>> torch.div(a, b, rounding_mode='floor')\n",
            "    tensor([[-1., -7.,  0.,  1.],\n",
            "            [ 0., -4., -2.,  6.],\n",
            "            [ 0.,  4., -1.,  5.],\n",
            "            [-1., -1., -2.,  6.]])\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten / b_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rrq9U9gDAu_",
        "outputId": "30ffb363-a587-45b5-b528-593e5863e0e1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5771, 0.6182, 1.1066],\n",
              "        [2.3338, 0.6108, 0.2816],\n",
              "        [1.1996, 0.5134, 0.0731]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.div(a_ten, b_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9blwBzyaEV6_",
        "outputId": "b30d3bb5-41e6-48da-a458-bc6c8edaea0e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5771, 0.6182, 1.1066],\n",
              "        [2.3338, 0.6108, 0.2816],\n",
              "        [1.1996, 0.5134, 0.0731]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Matrux multiptication:***"
      ],
      "metadata": {
        "id": "y3017mibDBUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.matmul.__doc__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT3HETbNFAnl",
        "outputId": "a2625dbe-0328-49c1-cc99-0656a620260d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "matmul(input, other, *, out=None) -> Tensor\n",
            "\n",
            "Matrix product of two tensors.\n",
            "\n",
            "The behavior depends on the dimensionality of the tensors as follows:\n",
            "\n",
            "- If both tensors are 1-dimensional, the dot product (scalar) is returned.\n",
            "- If both arguments are 2-dimensional, the matrix-matrix product is returned.\n",
            "- If the first argument is 1-dimensional and the second argument is 2-dimensional,\n",
            "  a 1 is prepended to its dimension for the purpose of the matrix multiply.\n",
            "  After the matrix multiply, the prepended dimension is removed.\n",
            "- If the first argument is 2-dimensional and the second argument is 1-dimensional,\n",
            "  the matrix-vector product is returned.\n",
            "- If both arguments are at least 1-dimensional and at least one argument is\n",
            "  N-dimensional (where N > 2), then a batched matrix multiply is returned.  If the first\n",
            "  argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the\n",
            "  batched matrix multiply and removed after.  If the second argument is 1-dimensional, a\n",
            "  1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.\n",
            "  The non-matrix (i.e. batch) dimensions are :ref:`broadcasted <broadcasting-semantics>` (and thus\n",
            "  must be broadcastable).  For example, if :attr:`input` is a\n",
            "  :math:`(j \\times 1 \\times n \\times n)` tensor and :attr:`other` is a :math:`(k \\times n \\times n)`\n",
            "  tensor, :attr:`out` will be a :math:`(j \\times k \\times n \\times n)` tensor.\n",
            "\n",
            "  Note that the broadcasting logic only looks at the batch dimensions when determining if the inputs\n",
            "  are broadcastable, and not the matrix dimensions. For example, if :attr:`input` is a\n",
            "  :math:`(j \\times 1 \\times n \\times m)` tensor and :attr:`other` is a :math:`(k \\times m \\times p)`\n",
            "  tensor, these inputs are valid for broadcasting even though the final two dimensions (i.e. the\n",
            "  matrix dimensions) are different. :attr:`out` will be a :math:`(j \\times k \\times n \\times p)` tensor.\n",
            "\n",
            "This operation has support for arguments with :ref:`sparse layouts<sparse-docs>`. In particular the\n",
            "matrix-matrix (both arguments 2-dimensional) supports sparse arguments with the same restrictions\n",
            "as :func:`torch.mm`\n",
            "\n",
            "\n",
            ".. warning::\n",
            "    Sparse support is a beta feature and some layout(s)/dtype/device combinations may not be supported,\n",
            "    or may not have autograd support. If you notice missing functionality please\n",
            "    open a feature request.\n",
            "\n",
            "This operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
            "\n",
            "On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
            "\n",
            ".. note::\n",
            "\n",
            "    The 1-dimensional dot product version of this function does not support an :attr:`out` parameter.\n",
            "\n",
            "Arguments:\n",
            "    input (Tensor): the first tensor to be multiplied\n",
            "    other (Tensor): the second tensor to be multiplied\n",
            "\n",
            "Keyword args:\n",
            "    out (Tensor, optional): the output tensor.\n",
            "\n",
            "Example::\n",
            "\n",
            "    >>> # vector x vector\n",
            "    >>> tensor1 = torch.randn(3)\n",
            "    >>> tensor2 = torch.randn(3)\n",
            "    >>> torch.matmul(tensor1, tensor2).size()\n",
            "    torch.Size([])\n",
            "    >>> # matrix x vector\n",
            "    >>> tensor1 = torch.randn(3, 4)\n",
            "    >>> tensor2 = torch.randn(4)\n",
            "    >>> torch.matmul(tensor1, tensor2).size()\n",
            "    torch.Size([3])\n",
            "    >>> # batched matrix x broadcasted vector\n",
            "    >>> tensor1 = torch.randn(10, 3, 4)\n",
            "    >>> tensor2 = torch.randn(4)\n",
            "    >>> torch.matmul(tensor1, tensor2).size()\n",
            "    torch.Size([10, 3])\n",
            "    >>> # batched matrix x batched matrix\n",
            "    >>> tensor1 = torch.randn(10, 3, 4)\n",
            "    >>> tensor2 = torch.randn(10, 4, 5)\n",
            "    >>> torch.matmul(tensor1, tensor2).size()\n",
            "    torch.Size([10, 3, 5])\n",
            "    >>> # batched matrix x broadcasted matrix\n",
            "    >>> tensor1 = torch.randn(10, 3, 4)\n",
            "    >>> tensor2 = torch.randn(4, 5)\n",
            "    >>> torch.matmul(tensor1, tensor2).size()\n",
            "    torch.Size([10, 3, 5])\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_ten @ b_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZYbmLsYDGoa",
        "outputId": "68f04b95-9a1f-4943-ebaa-3300ff9c41ab"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0321, 1.3431, 1.2234],\n",
              "        [0.7040, 0.9611, 1.0363],\n",
              "        [0.7146, 0.9121, 1.0771]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(a_ten, b_ten)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V3b7odBEbAa",
        "outputId": "0e78bf9f-7190-4946-dc41-2fb88a326798"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0321, 1.3431, 1.2234],\n",
              "        [0.7040, 0.9611, 1.0363],\n",
              "        [0.7146, 0.9121, 1.0771]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn_like(a_ten)\n",
        "b = torch.randn_like(a_ten)"
      ],
      "metadata": {
        "id": "gVGD8Y64EdQY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.matmul(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZWfTuHbFQZ-",
        "outputId": "6eb813ae-fa2f-4ae9-fd5c-63c3edc92562"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0885,  0.0451,  0.1910],\n",
              "        [-1.8015, -0.0083, -0.0930],\n",
              "        [ 0.0121, -0.1046,  1.9451]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JfFBOUOYFS5n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}